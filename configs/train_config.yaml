data:
  train_path: "data/train"
  test_path: "data/test"
  max_vocab_size: 20000
  max_seq_length: 256
  min_word_freq: 2

training:
  batch_size: 64
  epochs: 10
  learning_rate: 0.001
  weight_decay: 0.0001
  random_seed: 42
  gradient_clip: 1.0
  early_stopping_patience: 3
  validation_split: 0.1

model:
  embedding_dim: 128
  hidden_dim: 256
  num_layers: 2
  dropout: 0.3
  bidirectional: true

paths:
  model_save_dir: "models"
  log_dir: "logs"
  checkpoint_dir: "models/checkpoints"

logging:
  level: "INFO"
  log_every_n_steps: 100
  save_every_n_epochs: 1

device:
  use_cuda: true
  cuda_device: 0
