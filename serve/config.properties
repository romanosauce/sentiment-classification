# TorchServe configuration

# Disable token authorization
disable_token_authorization=true

# Inference API
inference_address=http://0.0.0.0:8080
# Management API
management_address=http://0.0.0.0:8081
# Metrics API
metrics_address=http://0.0.0.0:8082

# Model store location
model_store=/home/model-server/model-store

# Models to load at startup (comma-separated)
load_models=sentiment.mar

# Number of workers per model
number_of_netty_threads=4
job_queue_size=100

# Default workers
default_workers_per_model=1

# Response timeout (ms)
default_response_timeout=120

# Max request size (100MB)
max_request_size=104857600

# Enable metrics
enable_metrics_api=true
metrics_format=prometheus

# Logging
async_logging=false
